{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Backpropagation </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> Algoritam učenja iza neuronskih mreža </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadržaj notebooka:\n",
    "\n",
    "1. [Uvod u neuronske mreže](#intro)  - Kratki pregled što su neuronske mreže i kako rade. <br>\n",
    "    1.1 [Motivacija](#motiv) <br>\n",
    "    1.2 [Perceptroni](#perc) <br>\n",
    "    1.3 [Neuroni](#neuron) <br>\n",
    "    1.4 [Neuronske mreže](#nn) <br>\n",
    "2. [Učenje kroz prošlost](#past)  - Kako su neuronske mreže učile kroz prošlost? <br>\n",
    "3. [Backpropagation](#backprop)     - \"Moderni\" pristup učenju neuronskih mreža <br>\n",
    "4. [Zaključak](#conclusion)          - Prednosti i mane backpropagationa i što dalje? <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uvod u neuronske mreže <a name=\"intro\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivacija <a name=\"motiv\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>U konvencionalnom pristupu programiranju, ljudi su govorili računalu što da radi tako što su mu razbijali velike probleme na mnogo manjih, precizno definiranih problema koje je računalo moglo lako izvršavati.</p>\n",
    "<p>Neuronske mreže zauzimaju potpuno suprotni pristup načinu na koji smo dosada programirali. U neuronskim mrežama mi ne kažemo računalu kako da riješi naš problem. Umjesto toga, neuronske mreže uče promatrajući velike količine podataka, samostalno smišljajući rješenje predstavljenog problema.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Kako bi dobili predodžbu koliko su neuronske mreže inovativne zamislimo problem prepoznavanja znamenki. Prepoznavanje znamenki ne bi trebao biti lagan problem, ali mi ljudi smo izuzetno dobri u tome i često ne cijenimo koliko teške probleme naš mozak rješava na dnevnoj bazi. </p>\n",
    "\n",
    "<p> Tek nakon što pokušamo napisati program koji prepoznaje znamenke, postanemo svjesni problema - ono što nam se dosada činilo izuzetno laganim, odjednom postaje jako težak problem. Jednostavna intuicija iza toga kako mi prepoznajemo znamenke poput \"6 se sastoji od kružića i ravne crte iz donjeg lijevod u gornji desni kut\" je ne baš jednostavna za izraziti algoritamski. Čak i ako pokušamo jasno definirati pravila, izgubiti ćemo se u moru specijalnih slučajeva. </p>\n",
    "\n",
    "<p> Neuronske mreže uzimaju potpuno drukčiji pristup, nešto nalik tome kako smo mi učili brojeve. Ideja je da uzmemo veliku količinu napisaih brojeva i razvijemo sistem koji će učiti iz tih znamenki, odnosno sistem koji će sam definirati pravila kako raspoznati koja je koja znamenka. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptroni - prethodnik neurona <a name=\"perc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Da bi razumjeli što je neuronska mreža, prvo moramo razumjeti što je neuron. </p>\n",
    "\n",
    "<p>Prvo ćemo promotriti model *perceptrona*. Perceptron prima nekoliko binarnih vrijednosti $x_1$, $x_2$,..., $x_n$ i daje binarni rezultat tako što svakom ulaznom podatku $x_i$ daje \"važnost\" $\\omega_i$. Tu \"važnost\" $\\omega_i$ zvati ćemo težina. Rezultat, 0 ili 1, koji perceptron daje ovisi isključivo o tome je li $\\sum \\omega_i \\cdot x_i$ veća ili manja od neke praga. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ako zapišemo $x_i$ i $\\omega_i$ kao vektore $x$ i $\\omega$, te uvedemo bias $b=-$prag dobijemo sljedeći rezultat. </p>\n",
    "\n",
    "$$\n",
    "\\text{perceptron(x)} = \\left\\{\n",
    "    \\begin{array} \\\\\n",
    "        0, & \\ \\omega \\cdot x + b\\leq 0 \\\\\n",
    "        1, & \\ \\omega \\cdot x + b > 0 \\\\\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "<p> Stoga perceptron možemo promatrati kao model koji daje težinu nekim tvrdnjama i iz njih donosi zaključak. </p>\n",
    "\n",
    "Sada, ono što želimo postići je međusobno povezati te perceptrone i onda promjenama u težinama i biasu natjerati mrežu da uči. Kako bi mreža učila, ono što moram postići je da kada napravimo malu promjenu na težini ili na biasu dobijemo i malu promjenu na izlazu iz mreže. Međutim, problem kod perceptrona je što će mala promjena uzrokovati da se naš izlaz potpuno promjeni. \n",
    "\n",
    "Zašto je problem? Pretpostavimo da naša mreža dobro klasificira većinu brojeva, ali klasificira sliku kao 1, a trebala bi biti 7. Ako bi se malom promjenom na težinama dobivala mala promjena na izlazu, onda bi polako mogli natjerati naš program da klasificira tu sliku kao 7, minimalno utječući na to kako mreža reagira na ostale slike. Međutim ako je mreža napravljena od perceptrona, mala promjena koja će natjerati sliku da pokazuje na 7 usput će možda promijeniti i druge slike na potpuno nepredvidiv način."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuroni - osnovne gradivne jedinice <a name=\"neuron\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>U modelu perceptrona smo naišli na problem binarnog izlaza, odnosno kao izlaz vraća 0 ili 1. Kako bi rješili taj problem uvodimo aktivacijske funkcije i tako nastaju neuroni kakvi se i danas koriste. </p>\n",
    "\n",
    "<p> Koja je svrha aktivacijske funkcije? Recimo da želimo postići da umjesto da naš neuron vraća samo 0 ili 1, on ima mogućnost vratiti i sve vrijednosti između. Time smo postigli da mala promjena u nekoj od težina ne uzrokuje veliki flip sa 0 na 1 ili obratno. Kako bi dobili takav model neurona primjenjujemo aktivacijsku funkciju na njegov izlaz. </p>\n",
    "\n",
    "<p> Najčešće korištene aktivacijske funkcije su: </p>\n",
    "\n",
    "\\begin{align}\n",
    "    f(x) &= \\frac{1}{1 + e^{-x}}, \\ \\ \\ \\text{sigmoid funkcija} \\\\ \\\\\n",
    "    f(x) &= tanh(x), \\ \\ \\ \\ \\ \\text{tangens hiperbolni} \\\\ \\\\\n",
    "    f(x) &= max(0, x), \\ \\ \\text{ReLu funkcija}\n",
    "\\end{align}\n",
    "\n",
    "<br>\n",
    "<p> \n",
    "Uzmimo kao primjer sigmoid aktivacijsku funkciju.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuronske mreže <a name=\"nn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Učenje kroz prošlost <a name=\"past\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation <a name=\"backprop\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaključak <a name=\"conclusion\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
